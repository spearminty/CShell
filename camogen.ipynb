{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "camogen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlIr3RBdrVOBQFgn/nlJnu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spearminty/CShell/blob/master/camogen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "StyleGAN2-ADA only works with Tensorflow 1. Run the next cell before anything else to make sure we’re using TF1 and not TF2."
      ],
      "metadata": {
        "id": "XztRi-0SrUpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#core configurations \n",
        "dataset_name = 'camogen'\n",
        "resize_value = 512\n",
        "#used to identify a distinct lineage of training checkpoints\n",
        "network_name = 'network1'\n",
        "#use this to skip training epochs from script\n",
        "skip_training = False\n"
      ],
      "metadata": {
        "id": "TvdGQLtNf_iY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNJQPEIneypB",
        "outputId": "e35639a2-4b3b-4a72-de47-661af9ce3f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Fri Jun 24 03:40:03 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "content_path = Path('/').absolute() / 'content'\n",
        "drive_path = content_path / 'drive'\n",
        "drive.mount(str(drive_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEPz6GDYfGSp",
        "outputId": "9d761764-e271-4de2-dad1-c565bbf4da29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run this cell to install StyleGAN2-ADA on your Drive. If you’ve already installed the repository, it will skip the installation process and only check for updates. If you haven’t installed it, it will install all the necessary files. Beside, in, out, datasets and training folders are generated for data storage. Everything will be available on your Google Drive in the folder StyleGAN2-ADA even after closing this Notebook."
      ],
      "metadata": {
        "id": "sPZkc_9TfKwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stylegan2_repo_url  = 'https://github.com/dvschultz/stylegan2-ada' # or https://github.com/NVlabs/stylegan2-ada\n",
        "\n",
        "project_path        = drive_path / 'MyDrive' / 'train' / 'project' / dataset_name\n",
        "image_path          = drive_path / 'MyDrive' / 'train' / 'images' / 'camo1'\n",
        "stylegan2_repo_path = project_path / 'stylegan2-ada'\n",
        "\n",
        "# Create project folder if inexistant\n",
        "if not project_path.is_dir():\n",
        "    %mkdir \"{project_path}\"\n",
        "%cd \"{project_path}\"\n",
        "\n",
        "for dir in ['in', 'out', 'datasets', 'training']:\n",
        "    if not (project_path / dir).is_dir():\n",
        "        %mkdir {dir}\n",
        "if not (project_path / 'datasets' / 'source').is_dir():\n",
        "    %mkdir \"{project_path / 'datasets' / 'source'}\"\n",
        "\n",
        "# Download StyleGAN2-ada\n",
        "!git config --global user.name \"spearminty\"\n",
        "!git config --global user.email \"thx1134@gmail.com\"\n",
        "if stylegan2_repo_path.is_dir():\n",
        "    !git -C \"{stylegan2_repo_path}\" fetch origin\n",
        "    !git -C \"{stylegan2_repo_path}\" checkout origin/main -- *.py\n",
        "else:\n",
        "    print(\"Install StyleGAN2-ADA\")\n",
        "    !git clone {stylegan2_repo_url}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wPOaxlWfIYI",
        "outputId": "0de175c0-9e15-40bd-dc9a-a728d44150e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/train/project/camogen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a custom model"
      ],
      "metadata": {
        "id": "SSYpbA-XfSlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "resize the images"
      ],
      "metadata": {
        "id": "p1bTWz2nj0I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "training_resize_path = image_path / str(resize_value)\n",
        "\n",
        "print(f\"Looking for folder: {training_resize_path}\")\n",
        "\n",
        "if not os.path.isdir(training_resize_path):\n",
        "    os.mkdir(training_resize_path)\n",
        "    print(\"Resizing training images...\")\n",
        "\n",
        "# this resizes to square. consider cropping square first (if not square) then resize\n",
        "    training_data = []\n",
        "    iter = 0\n",
        "    for filename in tqdm(os.listdir(image_path)):\n",
        "        if (image_path / filename).is_dir():\n",
        "          continue\n",
        "        print(filename)\n",
        "        path = os.path.join(image_path,filename)\n",
        "        image = Image.open(path).resize((resize_value,\n",
        "            resize_value),Image.ANTIALIAS)\n",
        "        save_path = training_resize_path / filename\n",
        "        image.save(save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whyuPj3fhV_Z",
        "outputId": "f44cad2f-ef99-472e-e55e-e1405ff9008f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for folder: /content/drive/MyDrive/train/images/camo1/512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "process dataset and convert to tfr format"
      ],
      "metadata": {
        "id": "nhjgyyAQfe-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local_images_path = image_path / str(resize_value)\n",
        "local_dataset_path = project_path / 'tfr'\n",
        "\n",
        "if (local_dataset_path).is_dir():\n",
        "    print('\\N{Heavy Exclamation Mark Symbol} Dataset already created \\N{Heavy Exclamation Mark Symbol}')\n",
        "    print('Delete current dataset folder ({}) to regenerate tfrecords.'.format(local_dataset_path))\n",
        "else:\n",
        "    %mkdir \"{local_dataset_path}\"\n",
        "    !python \"{stylegan2_repo_path / 'dataset_tool.py'}\" create_from_images \\\n",
        "        \"{local_dataset_path}\" \"{local_images_path}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGgWmIxSfclQ",
        "outputId": "ee75703b-6c6f-451e-b2af-bb3af6d724ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❗ Dataset already created ❗\n",
            "Delete current dataset folder (/content/drive/MyDrive/train/project/camogen/tfr) to regenerate tfrecords.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here are numerous arguments to tune the training of your model. To obtain nice results, you will certainly have to experiment. Here are the most popular parameters:\n",
        "\n",
        "mirror: Should the images be mirrored vertically?\n",
        "\n",
        "mirrory: Should the images be mirrored horizontally?\n",
        "\n",
        "snap: How often should the model generate image samples and a network pickle (.pkl file)?\n",
        "\n",
        "resume: Network pickle to resume training from?\n",
        "\n",
        "To see all the options, run the following help cell.\n",
        "\n",
        "Please note that Google Colab Pro gives access to V100 GPUs, which drastically decreases (~3x) processing time over P100 GPUs."
      ],
      "metadata": {
        "id": "3ciVqRkCfj9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!python \"{stylegan2_repo_path / 'train.py'}\" --help"
      ],
      "metadata": {
        "id": "n_9lQOXbfl8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "def locate_latest_network(training_path):\n",
        "    latest_file = None\n",
        "    print(f\"Scanning {training_path}..\")\n",
        "    if training_path.is_dir():\n",
        "      list_of_files = glob.glob(f'{training_path}/**/*.pkl')\n",
        "      if len(list_of_files)>0:\n",
        "          latest_file = max(list_of_files, key=os.path.getctime)\n",
        "    print(latest_file)\n",
        "    return latest_file"
      ],
      "metadata": {
        "id": "cBrTlYW92Lz7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if skip_training:\n",
        "  exit()\n",
        "#tensor 1.x requires numpy 1.16 to function. \n",
        "#we just live with the error messages here and do not restart\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.16.4\n",
        "\n",
        "import numpy\n",
        "print(numpy.__version__)\n",
        "\n",
        "training_path = project_path / 'training' / dataset_name / network_name\n",
        "if not training_path.is_dir():\n",
        "    %mkdir \"{training_path}\"\n",
        "\n",
        "#how often should the model generate samples and a .pkl file\n",
        "snapshot_count = 10\n",
        "#should the images be mirrored left to right?\n",
        "mirrored = True\n",
        "#should the images be mirrored top to bottom?\n",
        "mirroredY = False\n",
        "#metrics? \n",
        "metric_list = None\n",
        "#augments\n",
        "augs = 'bgc'\n",
        "snap = 10\n",
        "resume_arg = ''\n",
        "\n",
        "#locate latest resume from\n",
        "latest_file = locate_latest_network(training_path)\n",
        "if latest_file != None:\n",
        "    resume = training_path / latest_file\n",
        "    print (f'located a resume from network for {network_name}: {latest_file} ')\n",
        "    resume_arg = f' --resume={resume}' \n",
        "    print(f'{resume_arg}')\n",
        "print(f'{local_dataset_path}')\n",
        "\n",
        "!python \"{stylegan2_repo_path / 'train.py'}\" --outdir=\"{training_path}\" \\\n",
        "    --data=\"{local_dataset_path}\" {resume_arg} \\\n",
        "    --snap={snapshot_count} --augpipe={augs} \\\n",
        "    --snap={snap} \\\n",
        "    --mirror={mirrored} --mirrory={mirroredY} \\\n",
        "    --metrics={metric_list} #--dry-run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QaclmE0WfmcA",
        "outputId": "d3be5476-a710-4136-b90d-639735d97b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.21.6\n",
            "Uninstalling numpy-1.21.6:\n",
            "  Successfully uninstalled numpy-1.21.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.16.4\n",
            "  Downloading numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 724 kB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lucid 0.3.10 requires umap-learn, which is not installed.\n",
            "tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.5.3 which is incompatible.\n",
            "xarray 0.20.2 requires numpy>=1.18, but you have numpy 1.16.4 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.16.4 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.16.4 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.16.4 which is incompatible.\n",
            "pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.16.4 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
            "pyarrow 6.0.1 requires numpy>=1.16.6, but you have numpy 1.16.4 which is incompatible.\n",
            "pandas 1.3.5 requires numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.16.4 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.16.4 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n",
            "jaxlib 0.3.7+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.16.4 which is incompatible.\n",
            "jax 0.3.8 requires numpy>=1.19, but you have numpy 1.16.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cupy-cuda111 9.4.0 requires numpy<1.24,>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.16.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.21.6\n",
            "Scanning /content/drive/MyDrive/train/project/camogen/training/camogen/network1..\n",
            "/content/drive/MyDrive/train/project/camogen/training/camogen/network1/00001-tfr-mirror-auto1-bgc-resumecustom/network-snapshot-000040.pkl\n",
            "located a resume from network for network1: /content/drive/MyDrive/train/project/camogen/training/camogen/network1/00001-tfr-mirror-auto1-bgc-resumecustom/network-snapshot-000040.pkl \n",
            " --resume=/content/drive/MyDrive/train/project/camogen/training/camogen/network1/00001-tfr-mirror-auto1-bgc-resumecustom/network-snapshot-000040.pkl\n",
            "/content/drive/MyDrive/train/project/camogen/tfr\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_args\": {\n",
            "    \"func_name\": \"training.networks.G_main\",\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"mapping_layers\": 2,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"D_args\": {\n",
            "    \"func_name\": \"training.networks.D_main\",\n",
            "    \"mbstd_group_size\": 4,\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.0025\n",
            "  },\n",
            "  \"D_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.0025\n",
            "  },\n",
            "  \"loss_args\": {\n",
            "    \"func_name\": \"training.loss.stylegan2\",\n",
            "    \"r1_gamma\": 6.5536\n",
            "  },\n",
            "  \"augment_args\": {\n",
            "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
            "    \"tune_heuristic\": \"rt\",\n",
            "    \"tune_target\": 0.6,\n",
            "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
            "    \"apply_args\": {\n",
            "      \"xflip\": 1,\n",
            "      \"rotate90\": 1,\n",
            "      \"xint\": 1,\n",
            "      \"scale\": 1,\n",
            "      \"rotate\": 1,\n",
            "      \"aniso\": 1,\n",
            "      \"xfrac\": 1,\n",
            "      \"brightness\": 1,\n",
            "      \"contrast\": 1,\n",
            "      \"lumaflip\": 1,\n",
            "      \"hue\": 1,\n",
            "      \"saturation\": 1\n",
            "    },\n",
            "    \"tune_kimg\": 100\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"train_dataset_args\": {\n",
            "    \"path\": \"/content/drive/MyDrive/train/project/camogen/tfr\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"use_raw\": false,\n",
            "    \"resolution\": 512,\n",
            "    \"mirror_augment\": true,\n",
            "    \"mirror_augment_v\": false\n",
            "  },\n",
            "  \"metric_arg_list\": [],\n",
            "  \"metric_dataset_args\": {\n",
            "    \"path\": \"/content/drive/MyDrive/train/project/camogen/tfr\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"use_raw\": false,\n",
            "    \"resolution\": 512,\n",
            "    \"mirror_augment\": true,\n",
            "    \"mirror_augment_v\": false\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"minibatch_size\": 8,\n",
            "  \"minibatch_gpu\": 8,\n",
            "  \"G_smoothing_kimg\": 2.5,\n",
            "  \"G_smoothing_rampup\": null,\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/train/project/camogen/training/camogen/network1/00001-tfr-mirror-auto1-bgc-resumecustom/network-snapshot-000040.pkl\",\n",
            "  \"run_dir\": \"/content/drive/MyDrive/train/project/camogen/training/camogen/network1/00002-tfr-mirror-auto1-bgc-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:  /content/drive/MyDrive/train/project/camogen/training/camogen/network1/00002-tfr-mirror-auto1-bgc-resumecustom\n",
            "Training data:     /content/drive/MyDrive/train/project/camogen/tfr\n",
            "Training length:   25000 kimg\n",
            "Resolution:        512\n",
            "Number of GPUs:    1\n",
            "\n",
            "Creating output directory...\n",
            "Loading training set...\n",
            "Image shape: [3, 512, 512]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
            "Resuming from \"/content/drive/MyDrive/train/project/camogen/training/camogen/network1/00001-tfr-mirror-auto1-bgc-resumecustom/network-snapshot-000040.pkl\"\n",
            "\n",
            "G                             Params    OutputShape         WeightShape     \n",
            "---                           ---       ---                 ---             \n",
            "latents_in                    -         (?, 512)            -               \n",
            "labels_in                     -         (?, 0)              -               \n",
            "epochs                        1         ()                  ()              \n",
            "epochs_1                      1         ()                  ()              \n",
            "G_mapping/Normalize           -         (?, 512)            -               \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Broadcast           -         (?, 16, 512)        -               \n",
            "dlatent_avg                   -         (512,)              -               \n",
            "Truncation/Lerp               -         (?, 16, 512)        -               \n",
            "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n",
            "G_synthesis/512x512/Conv0_up  139457    (?, 64, 512, 512)   (3, 3, 128, 64) \n",
            "G_synthesis/512x512/Conv1     69761     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
            "G_synthesis/512x512/Upsample  -         (?, 3, 512, 512)    -               \n",
            "G_synthesis/512x512/ToRGB     33027     (?, 3, 512, 512)    (1, 1, 64, 3)   \n",
            "---                           ---       ---                 ---             \n",
            "Total                         28700649                                      \n",
            "\n",
            "\n",
            "D                    Params    OutputShape         WeightShape     \n",
            "---                  ---       ---                 ---             \n",
            "images_in            -         (?, 3, 512, 512)    -               \n",
            "labels_in            -         (?, 0)              -               \n",
            "512x512/FromRGB      256       (?, 64, 512, 512)   (1, 1, 3, 64)   \n",
            "512x512/Conv0        36928     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
            "512x512/Conv1_down   73856     (?, 128, 256, 256)  (3, 3, 64, 128) \n",
            "512x512/Skip         8192      (?, 128, 256, 256)  (1, 1, 64, 128) \n",
            "256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n",
            "256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n",
            "128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n",
            "128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n",
            "64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n",
            "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
            "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
            "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
            "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
            "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
            "Output               513       (?, 1)              (512, 1)        \n",
            "---                  ---       ---                 ---             \n",
            "Total                28982849                                      \n",
            "\n",
            "Exporting sample images...\n",
            "Replicating networks across 1 GPUs...\n",
            "Initializing augmentations...\n",
            "Setting up optimizers...\n",
            "Constructing training graph...\n",
            "Finalizing training ops...\n",
            "Initializing metrics...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 2m 40s       sec/tick 31.5    sec/kimg 984.44  maintenance 128.0  gpumem 10.0  augment 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can finally generate images using a pre-trained network once everything is set-up. "
      ],
      "metadata": {
        "id": "buUys8Atfqeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install opensimplex\n",
        "!python \"{stylegan2_repo_path / 'generate.py'}\" generate-images --help "
      ],
      "metadata": {
        "id": "dgc91CdzfoOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import random\n",
        "import os\n",
        "seed_init = random.randint(10000)\n",
        "nbr_images = 6\n",
        "generation_from=None\n",
        "\n",
        "#uncomment below to enable this code block to generate images directly by training pickle file path\n",
        "#generation_from = '/content/drive/MyDrive/train/project/camogen/out/012.pkl'\n",
        "\n",
        "stylegan2_repo_url  = 'https://github.com/dvschultz/stylegan2-ada' # or https://github.com/NVlabs/stylegan2-ada\n",
        "stylegan2_repo_path = '/content/drive/MyDrive/train/project/camogen/stylegan2-ada'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%tensorflow_version 1.x\n",
        "!nvidia-smi\n",
        "# Download StyleGAN2-ada\n",
        "!git config --global user.name \"spearminty\"\n",
        "!git config --global user.email \"thx1134@gmail.com\"\n",
        "if os.path.exists(stylegan2_repo_path):\n",
        "    !git -C \"{stylegan2_repo_path}\" fetch origin\n",
        "    !git -C \"{stylegan2_repo_path}\" checkout origin/main -- *.py\n",
        "else:\n",
        "    print(\"Install StyleGAN2-ADA\")\n",
        "    !git clone {stylegan2_repo_url}\n",
        "%pip install opensimplex\n",
        "\n",
        "if generation_from == None:\n",
        "  latest_file = locate_latest_network(training_path)\n",
        "  if latest_file != None:\n",
        "      generation_from = training_path / latest_file\n",
        "  if generation_from == None:\n",
        "    print(\"Could not locate valid network checkpoint!\")\n",
        "    exit()\n",
        "\n",
        "!python \"{os.path.join(stylegan2_repo_path, 'generate.py')}\" generate-images \\\n",
        "      --outdir=\"{'/content/drive/MyDrive/train/project/camogen/out'}\" --trunc=0.7 \\\n",
        "      --seeds={seed_init}-{seed_init+nbr_images-1} --create-grid \\\n",
        "      --network={generation_from}"
      ],
      "metadata": {
        "id": "eB0QJse0fs3B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}